{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers scipy diffusers accelerate opencv-python pandas tqdm typed-argument-parser"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPrbps-XSCDL",
        "outputId": "d2413fe0-2a39-417c-ea1c-520da1f7bef4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Collecting diffusers\n",
            "  Downloading diffusers-0.30.1-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\n",
            "Collecting typed-argument-parser\n",
            "  Downloading typed_argument_parser-1.10.1-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (8.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.4.0+cu121)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.10/dist-packages (from typed-argument-parser) (0.16)\n",
            "Collecting typing-inspect>=0.7.1 (from typed-argument-parser)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.7.1->typed-argument-parser)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.20.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading diffusers-0.30.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typed_argument_parser-1.10.1-py3-none-any.whl (30 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, typing-inspect, typed-argument-parser, diffusers\n",
            "Successfully installed diffusers-0.30.1 mypy-extensions-1.0.0 typed-argument-parser-1.10.1 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiJb_MOBynO-",
        "outputId": "ab3f1b12-07b9-4667-8f37-1be3c9913d60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: torch\n",
            "Version: 2.4.0+cu121\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
            "Required-by: accelerate, fastai, torchaudio, torchvision\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install natten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ql2p3rByo_h",
        "outputId": "47150da1-1ec2-4815-fc0b-cebd51741c0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natten\n",
            "  Downloading natten-0.17.1.tar.gz (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from natten) (24.1)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from natten) (2.4.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->natten) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->natten) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->natten) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->natten) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->natten) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->natten) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->natten) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->natten) (1.3.0)\n",
            "Building wheels for collected packages: natten\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: create a folder images in os.cwd and put all .png files in cwd in the newly created folder\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import shutil\n",
        "\n",
        "# Create the 'images' folder if it doesn't exist\n",
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "# Get all .png files in the current working directory\n",
        "png_files = glob(\"*.jpeg\")\n",
        "\n",
        "# Move the .png files to the 'images' folder\n",
        "for file in png_files:\n",
        "  shutil.move(file, \"images\")\n"
      ],
      "metadata": {
        "id": "jKwmH0fhUUhh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD2eNImPN6lR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "a2978350-d844-4702-86aa-184389bd3629"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to import transformers.models.oneformer.processing_oneformer because of the following error (look up to see its traceback):\nNo module named 'torch._custom_ops'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1566\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1567\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/oneformer/processing_oneformer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mProcessorMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_torch_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdynamic_module_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcustom_object_save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_vision_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torchvision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_custom_ops\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch._custom_ops'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-7c9defbf9d90>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneFormerProcessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOneFormerForUniversalSegmentation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module {self.__name__} has no attribute {name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1555\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m             \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_class_to_module\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/import_utils.py\u001b[0m in \u001b[0;36m_get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1567\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1569\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   1570\u001b[0m                 \u001b[0;34mf\"Failed to import {self.__name__}.{module_name} because of the following error (look up to see its\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1571\u001b[0m                 \u001b[0;34mf\" traceback):\\n{e}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.oneformer.processing_oneformer because of the following error (look up to see its traceback):\nNo module named 'torch._custom_ops'"
          ]
        }
      ],
      "source": [
        "from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\n",
        "from PIL import Image, ImageFilter\n",
        "import numpy as np\n",
        "import torch\n",
        "from typing import Union\n",
        "from diffusers import AutoPipelineForInpainting, DEISMultistepScheduler, StableDiffusionInpaintPipeline\n",
        "from transformers import pipeline\n",
        "from transformers import AutoImageProcessor, AutoModelForDepthEstimation\n",
        "import cv2\n",
        "from glob import glob\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "from segmentation_colors import ade_palette, map_colors_rgb\n",
        "\n",
        "processor = OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_ade20k_dinat_large\")\n",
        "model = OneFormerForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_ade20k_dinat_large\")\n",
        "model = model.cuda()\n",
        "\n",
        "pipe = AutoPipelineForInpainting.from_pretrained('lykon/absolute-reality-1.6525-inpainting', torch_dtype=torch.float16, variant=\"fp16\")\n",
        "pipe.scheduler = DEISMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "depth_image_processor = AutoImageProcessor.from_pretrained(\"LiheYoung/depth-anything-large-hf\", torch_dtype=torch.float16)\n",
        "depth_model = AutoModelForDepthEstimation.from_pretrained(\"LiheYoung/depth-anything-large-hf\", torch_dtype=torch.float16)\n",
        "depth_model = depth_model.cuda()\n",
        "\n",
        "def resize_image(input_image, resolution, interpolation=None):\n",
        "    H, W, C = input_image.shape\n",
        "    H = float(H)\n",
        "    W = float(W)\n",
        "    k = float(resolution) / max(H, W)\n",
        "    H *= k\n",
        "    W *= k\n",
        "    H = int(np.round(H / 64.0)) * 64\n",
        "    W = int(np.round(W / 64.0)) * 64\n",
        "    if interpolation is None:\n",
        "        interpolation = cv2.INTER_LANCZOS4 if k > 1 else cv2.INTER_AREA\n",
        "    img = cv2.resize(input_image, (W, H), interpolation=interpolation)\n",
        "    return img\n",
        "\n",
        "def HWC3(x):\n",
        "    assert x.dtype == np.uint8\n",
        "    if x.ndim == 2:\n",
        "        x = x[:, :, None]\n",
        "    assert x.ndim == 3\n",
        "    H, W, C = x.shape\n",
        "    assert C == 1 or C == 3 or C == 4\n",
        "    if C == 3:\n",
        "        return x\n",
        "    if C == 1:\n",
        "        return np.concatenate([x, x, x], axis=2)\n",
        "    if C == 4:\n",
        "        color = x[:, :, 0:3].astype(np.float32)\n",
        "        alpha = x[:, :, 3:4].astype(np.float32) / 255.0\n",
        "        y = color * alpha + 255.0 * (1.0 - alpha)\n",
        "        y = y.clip(0, 255).astype(np.uint8)\n",
        "        return y\n",
        "\n",
        "\n",
        "def get_segmentation_of_room(image: Image) -> tuple[np.ndarray, Image]:\n",
        "    # Semantic Segmentation\n",
        "    with torch.inference_mode():\n",
        "        semantic_inputs = processor(images=image, task_inputs=[\"semantic\"], return_tensors=\"pt\")\n",
        "        semantic_inputs = {key: value.to(\"cuda\") for key, value in semantic_inputs.items()}\n",
        "        semantic_outputs = model(**semantic_inputs)\n",
        "        # pass through image_processor for postprocessing\n",
        "        predicted_semantic_map = \\\n",
        "        processor.post_process_semantic_segmentation(semantic_outputs, target_sizes=[image.size[::-1]])[0]\n",
        "\n",
        "    predicted_semantic_map = predicted_semantic_map.cpu()\n",
        "    color_seg = np.zeros((predicted_semantic_map.shape[0], predicted_semantic_map.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "    palette = np.array(ade_palette())\n",
        "    for label, color in enumerate(palette):\n",
        "        color_seg[predicted_semantic_map == label, :] = color\n",
        "\n",
        "    color_seg = color_seg.astype(np.uint8)\n",
        "    seg_image = Image.fromarray(color_seg).convert('RGB')\n",
        "    return color_seg, seg_image\n",
        "\n",
        "\n",
        "def filter_items(\n",
        "    colors_list: Union[list, np.ndarray],\n",
        "    items_list: Union[list, np.ndarray],\n",
        "    items_to_remove: Union[list, np.ndarray]\n",
        "):\n",
        "    filtered_colors = []\n",
        "    filtered_items = []\n",
        "    for color, item in zip(colors_list, items_list):\n",
        "        if item not in items_to_remove:\n",
        "            filtered_colors.append(color)\n",
        "            filtered_items.append(item)\n",
        "    return filtered_colors, filtered_items\n",
        "\n",
        "\n",
        "def get_inpating_mask(segmentation_mask: np.ndarray) -> Image:\n",
        "    unique_colors = np.unique(segmentation_mask.reshape(-1, segmentation_mask.shape[2]), axis=0)\n",
        "    unique_colors = [tuple(color) for color in unique_colors]\n",
        "    segment_items = [map_colors_rgb(i) for i in unique_colors]\n",
        "\n",
        "    control_items = [\"windowpane;window\", \"wall\", \"floor;flooring\",\"ceiling\",  \"sconce\", \"door;double;door\", \"light;light;source\",\n",
        "                     \"painting;picture\", \"stairs;steps\",\"escalator;moving;staircase;moving;stairway\"]\n",
        "    chosen_colors, segment_items = filter_items(\n",
        "                colors_list=unique_colors,\n",
        "                items_list=segment_items,\n",
        "                items_to_remove=control_items\n",
        "            )\n",
        "\n",
        "    mask = np.zeros_like(segmentation_mask)\n",
        "    for color in chosen_colors:\n",
        "        color_matches = (segmentation_mask == color).all(axis=2)\n",
        "        mask[color_matches] = 1\n",
        "\n",
        "    mask_image = Image.fromarray((mask * 255).astype(np.uint8)).convert(\"RGB\")\n",
        "    # enlarge mask region so that it also will erase the neighborhood of masked stuff\n",
        "    mask_image = mask_image.filter(ImageFilter.MaxFilter(25))\n",
        "    return mask_image\n",
        "\n",
        "def cleanup_room(image: Image, mask: Image) -> Image:\n",
        "    inpaint_prompt = \"Empty room, with only empty walls, floor, ceiling, doors, windows\"\n",
        "    negative_prompt = \"furnitures, sofa, cough, table, plants, rug, home equipment, music equipment, shelves, books, light, lamps, window, radiator\"\n",
        "    image_source_for_inpaint = image.resize((512, 512))\n",
        "    image_mask_for_inpaint = mask.resize((512, 512))\n",
        "    generator = [torch.Generator(device=\"cuda\").manual_seed(20)]\n",
        "\n",
        "    image_inpainting_auto = \\\n",
        "    pipe(prompt=inpaint_prompt, negative_prompt=negative_prompt, generator=generator, strentgh=0.8,\n",
        "         image=image_source_for_inpaint, mask_image=image_mask_for_inpaint, guidance_scale=10.0,\n",
        "         num_inference_steps=10).images[0]\n",
        "    image_inpainting_auto = image_inpainting_auto.resize((image.size[0], image.size[1]))\n",
        "    return image_inpainting_auto\n",
        "\n",
        "\n",
        "def get_depth_image(image: Image) -> Image:\n",
        "    image_to_depth = depth_image_processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
        "    with torch.no_grad():\n",
        "        depth_map = depth_model(**image_to_depth).predicted_depth\n",
        "\n",
        "    width, height = image.size\n",
        "    depth_map = torch.nn.functional.interpolate(\n",
        "        depth_map.unsqueeze(1).float(),\n",
        "        size=(height, width),\n",
        "        mode=\"bicubic\",\n",
        "        align_corners=False,\n",
        "    )\n",
        "    depth_min = torch.amin(depth_map, dim=[1, 2, 3], keepdim=True)\n",
        "    depth_max = torch.amax(depth_map, dim=[1, 2, 3], keepdim=True)\n",
        "    depth_map = (depth_map - depth_min) / (depth_max - depth_min)\n",
        "    image = torch.cat([depth_map] * 3, dim=1)\n",
        "\n",
        "    image = image.permute(0, 2, 3, 1).cpu().numpy()[0]\n",
        "    image = Image.fromarray((image * 255.0).clip(0, 255).astype(np.uint8))\n",
        "    return image\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    save_dir = \"clean_images/\"\n",
        "    image_paths = \"images/\"\n",
        "    all_images = glob(f\"{image_paths}/*\")\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    for elem in tqdm(all_images):\n",
        "        image_id = os.path.basename(elem).split(\".\")[0]\n",
        "        image = Image.open(elem)\n",
        "        color_map, segmentation_map = get_segmentation_of_room(image)\n",
        "        inpaiting_mask = get_inpating_mask(color_map)\n",
        "        clean_room = cleanup_room(image, inpaiting_mask)\n",
        "        color_map_clean, segmentation_map_clean_room = get_segmentation_of_room(clean_room)\n",
        "        depth_clean_room = get_depth_image(clean_room)\n",
        "\n",
        "        clean_room.save(os.path.join(save_dir, image_id+\"clean.png\"))\n",
        "        segmentation_map_clean_room.save(os.path.join(save_dir, image_id+\"segmentation.png\"))\n",
        "        depth_clean_room.save(os.path.join(save_dir, image_id+\"depth.png\"))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7pBF1Oe9UnM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}